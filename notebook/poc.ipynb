{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cinKw93Ei9_",
        "outputId": "5c3595ef-2c2a-432c-d723-e3174ba2762f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai-whisper in d:\\langchain\\code\\venv\\lib\\site-packages (20240930)\n",
            "Requirement already satisfied: numba in d:\\langchain\\code\\venv\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
            "Requirement already satisfied: numpy in d:\\langchain\\code\\venv\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in d:\\langchain\\code\\venv\\lib\\site-packages (from openai-whisper) (2.6.0)\n",
            "Requirement already satisfied: tqdm in d:\\langchain\\code\\venv\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in d:\\langchain\\code\\venv\\lib\\site-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in d:\\langchain\\code\\venv\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in d:\\langchain\\code\\venv\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\langchain\\code\\venv\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in d:\\langchain\\code\\venv\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in d:\\langchain\\code\\venv\\lib\\site-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\langchain\\code\\venv\\lib\\site-packages (from torch->openai-whisper) (4.13.1)\n",
            "Requirement already satisfied: networkx in d:\\langchain\\code\\venv\\lib\\site-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in d:\\langchain\\code\\venv\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in d:\\langchain\\code\\venv\\lib\\site-packages (from torch->openai-whisper) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in d:\\langchain\\code\\venv\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\langchain\\code\\venv\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: colorama in d:\\langchain\\code\\venv\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\langchain\\code\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\langchain\\code\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\langchain\\code\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\langchain\\code\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\langchain\\code\\venv\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35B1epRVFn2j",
        "outputId": "e1fd392f-1541-4a8b-dc24-c944ccd51afb"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "model_name = \"base\"\n",
        "model = whisper.load_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\langchain\\\\code\\\\AI_assistent\\\\notebook'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive D is Drive\n",
            " Volume Serial Number is 364B-3727\n",
            "\n",
            " Directory of d:\\langchain\\code\\AI_assistent\\notebook\n",
            "\n",
            "10-04-2025  08:58    <DIR>          .\n",
            "10-04-2025  08:54    <DIR>          ..\n",
            "10-04-2025  08:53           125,222 audio.mp3\n",
            "10-04-2025  09:25            30,423 poc.ipynb\n",
            "10-04-2025  07:27               576 run_bash.py\n",
            "               3 File(s)        156,221 bytes\n",
            "               2 Dir(s)  215,618,813,952 bytes free\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl35kdbgFBS8",
        "outputId": "325d97a7-2caa-4c51-b66e-556692e788db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\langchain\\code\\venv\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] The system cannot find the file specified",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m      5\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mlangchain\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAI_assistent\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33motebook\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[33mudio.mp3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m res = \u001b[43mcall_whisper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(res)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mcall_whisper\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_whisper\u001b[39m(path):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain\\code\\venv\\Lib\\site-packages\\whisper\\transcribe.py:133\u001b[39m, in \u001b[36mtranscribe\u001b[39m\u001b[34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[39m\n\u001b[32m    130\u001b[39m     decode_options[\u001b[33m\"\u001b[39m\u001b[33mfp16\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m mel = \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m content_frames = mel.shape[-\u001b[32m1\u001b[39m] - N_FRAMES\n\u001b[32m    135\u001b[39m content_duration = \u001b[38;5;28mfloat\u001b[39m(content_frames * HOP_LENGTH / SAMPLE_RATE)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain\\code\\venv\\Lib\\site-packages\\whisper\\audio.py:140\u001b[39m, in \u001b[36mlog_mel_spectrogram\u001b[39m\u001b[34m(audio, n_mels, padding, device)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.is_tensor(audio):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m         audio = \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     audio = torch.from_numpy(audio)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain\\code\\venv\\Lib\\site-packages\\whisper\\audio.py:58\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(file, sr)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     out = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.stdout\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.stderr.decode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1540\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1554\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1555\u001b[39m                          errread, errwrite)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified"
          ]
        }
      ],
      "source": [
        "def call_whisper(path):\n",
        "    result = model.transcribe(path)\n",
        "    return result\n",
        "\n",
        "path = \"D:\\langchain\\code\\AI_assistent\\notebook\\audio.mp3\"\n",
        "res = call_whisper(path = path)[\"text\"]\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiRwnBy1GcQA",
        "outputId": "8112af1e-0d57-4036-e3e4-2b795ea58988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_mistralai\n",
            "  Downloading langchain_mistralai-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.28.1)\n",
            "Collecting httpx-sse<1,>=0.3.1 (from langchain_mistralai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.3.33)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (2.10.6)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.21.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain_mistralai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (0.3.4)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (2.27.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain_mistralai) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (4.67.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_mistralai) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain_mistralai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2.3.0)\n",
            "Downloading langchain_mistralai-0.2.6-py3-none-any.whl (15 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: httpx-sse, langchain_mistralai\n",
            "Successfully installed httpx-sse-0.4.0 langchain_mistralai-0.2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl0gZ43-HQ1b",
        "outputId": "8c5a2e5e-1ff6-4b4c-9c85-a8e95e854eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API key: ··········\n"
          ]
        }
      ],
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J6YjotwcHaMH"
      },
      "outputs": [],
      "source": [
        "mistral_model_name = \"mistral-large-latest\"\n",
        "temprature = 0.2\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "\n",
        "mistral_model = ChatMistralAI(\n",
        "    model_name=mistral_model_name,\n",
        "    temprature=temprature,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsqSdO9dIVJg",
        "outputId": "2c3dfb60-9e87-42eb-85c7-035896f3a056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp C:\\\\Users\\\\USER\\\\Desktop\\\\main.py C:\\\\Users\\\\USER\\\\Desktop\\\\resume\\ edits\\\\\n"
          ]
        }
      ],
      "source": [
        "def make_mistral_call(command):\n",
        "    messages = [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that return the windows command for the instruction given to you by the human. Make sure to only return the bash command and in correct format and nothing else. The default path is 'C: Users USER'. Add backslash at appropriate places\",\n",
        "        ),\n",
        "        (\"human\", f\"{command}\")]\n",
        "    ai_msg = mistral_model.invoke(messages)\n",
        "    return ai_msg.content\n",
        "\n",
        "bash_command = make_mistral_call(command = \"copy main.py in the desktop to the resume edits folder at desktop\")\n",
        "print(bash_command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbl1CHV2JcWE"
      },
      "outputs": [],
      "source": [
        "bash_command.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvMVoDQ5JrN3"
      },
      "outputs": [],
      "source": [
        "import shlex\n",
        "import subprocess\n",
        "\n",
        "def make_bash_runnable(command):\n",
        "    \"\"\"\n",
        "    Fixes incorrect path escapes and runs the command in Bash.\n",
        "    Args:\n",
        "    command (str): The shell command with potential escape issues.\n",
        "\n",
        "    Returns:\n",
        "    tuple: (exit_code, output, error)\n",
        "    \"\"\"\n",
        "    # Split the command correctly\n",
        "    fixed_command = shlex.split(command)\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(fixed_command, capture_output=True, text=True)\n",
        "        return result.returncode, result.stdout, result.stderr\n",
        "    except Exception as e:\n",
        "        return -1, \"\", str(e)\n",
        "\n",
        "# Example Usage\n",
        "cmd = r'cp \"C:\\\\Users\\\\USER\\\\Desktop\\\\main.py\" \"C:\\\\Users\\\\USER\\\\Desktop\\\\resume edit\\\\\"'  # Your problematic command\n",
        "exit_code, output, error = make_bash_runnable(cmd)\n",
        "\n",
        "print(\"Exit Code:\", exit_code)\n",
        "print(\"Output:\", output)\n",
        "print(\"Error:\", error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFthI6k_KMHx"
      },
      "outputs": [],
      "source": [
        "!cp \"C:\\Users\\USER\\Desktop\\logo.png\" \"C:\\\\Users\\\\USER\\\\Desktop\\\\resume edit\\\\\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcpjgZd_MYzo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
